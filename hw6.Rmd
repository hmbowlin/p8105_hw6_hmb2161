---
title: "Homework 6"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(MASS)
library(modelr)
library(mgcv)
library(leaps)
library(p8105.datasets)
library(rnoaa)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```

# Problem 1: tidying
```{r}
## load in dataset

birth_data = 
  read_csv(file = "./data/birthweight.csv")

## clean dataset and convert categorical variables to factors
birth_data %>%
  janitor::clean_names() %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))

## check for missing data

birth_data %>%
  map_df(~sum(is.na(.)))

```
I loaded the dataset, cleaned it as appropriate data types, and checked for missing values. There are none so I can proceed with analyses.

## stepwise linear model

I am using a stepwise model building process to test what variables are associated with birth weight in my dataset. I 

```{r}
set.seed(10)
# pulling all of my variables into one equation
model_1 = lm(bwt ~ ., data = birth_data)

# doing a stepwise model selection based on AIC
model1_step = stepAIC(model_1, direction = "both", trace = FALSE) 

# summarizing the above model
summary(model1_step) 

# bwt = babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken

# plotting the residuals
plot(model1_step, scale = "r2")

# plot model residuals against fitted values

birth_data %>%
  add_predictions(model1_step) %>%
  add_residuals(model1_step) %>%
  ggplot(aes(x = pred, y = resid, color = pred)) +
  geom_point() +
  viridis::scale_color_viridis(discrete = FALSE) +
  labs(x = "Predicted Value",
       y = "Residual",
       title = "Residual by Predicted Value")

```
The variables selected into the model are: baby's sex, baby head circumference, baby's length at birth, mother's weight at delivery, family income, gestional age in weeks, mother's height, mother's race, number of live births prior to pregnancy, mother's pre-pregnancy weight, and average number of cigarettes smoked per day during pregnancy.

The residuals demonstrate a slight skew as they are centered to the right, but the cluster itself does not have a distinguishable pattern.

## cross validation
```{r}
# model 2 from problem set
model_2 = lm(bwt ~ blength + gaweeks, data = birth_data) %>%
  broom::tidy()

# model 3 from problem set
model_3 = lm(bwt ~ bhead*blength*babysex, data = birth_data) %>%
  broom::tidy()

# create cross val data frame
 cross_val = 
   crossv_mc(birth_data, 100) %>%
   mutate(
     train = map(train, as_tibble),
     test = map(test, as_tibble)
   )

# actual cross val of the three models to find best model
crossval = 
  cross_val %>%
  mutate(model1_step = map(train, ~lm(bwt ~ ., data = .x) %>%
                         stepAIC(direction = "both", trace = FALSE)),
         model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*babysex*blength, data = .x))) %>%
  mutate(rmse_model1_step = map2_dbl(model1_step, test, ~rmse(model = .x, data = .y)),
         rmse_model_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
         rmse_model_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))

crossval

# prediction error distribution for each model

crossval %>%
  pivot_longer(
    rmse_model1_step:rmse_model_3,
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse, color = model)) +
  geom_violin(aes(color = model)) +
  viridis::scale_color_viridis(discrete = TRUE) +
  labs(
    x = "Model",
    y = "rmse",
    title = "Model by Prediction Error Distribution"
  )
```
Given the high interpretability of each of these models, I will look at predicted error distributino to choose my model. Based on the violin plots above, model 1 provides the lowest predicted error distribution. I will choose the stepwise model I created as it has the lowest error, and through the stepwise process it has the smallest AIC and biggest log likelihood with the fewest number of parameters. 

Model chosen: y = $/beta_0$ + $\beta_1$babysex + $\beta_2$bhead + $\beta_3$blength + $\beta_4$delwt + $\beta_5$fincome + $\beta_6$gaweeks + $\beta_7$meight + $\beta_8$momage + $\beta_9$mrace + $\beta_10$parity + $\beta_11$ppwt + $\beta_12$smoken

Model chosen: y = -6246.367 + 32.317babysex + 134.4298head + 76.376blength + 3.956delwt + 0.6597fincome + 12.039gaweeks + 5.44meight + 3.454momage + -53.499mrace + 89.967parity + -2.832ppwt + -3.711smoken



# Problem 2: rsquared 
```{r}
# loading in weather dataset
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything())

# creating function to bootstrap

lm(tmax ~ tmin, data = weather_df) %>%
  broom::glance()

# drawing bootstrap samples with r^2
rsq_df =  
  weather_df %>%
  modelr::bootstrap(n = 5000) %>%
    mutate(
      models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
      results = map(models, broom::glance)) %>%
  dplyr::select(results) %>%
  unnest(results) %>%
  janitor::clean_names()

# graph of r^2

rsq_plot = 
  ggplot(rsq_df, aes(x = r_squared)) +
  geom_density() +
  labs(
    x = "R-Squared Value",
    y = "Density",
    title = "R-Squared Value Across Bootstrap Samples"
  )

print(rsq_plot)

quantile(pull(rsq_df, r_squared), 0.025)
quantile(pull(rsq_df, r_squared), 0.975)

```

# log beta0*beta1 graph
```{r}
# drawing bootstrap samples with log beta0*beta1
## pivoted wider and mutated to create the log(beta0*beta1) variable by multiplying intercept and tmin together

betas_df = 
  weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>%
  dplyr::select(results, .id) %>%
  unnest(results) %>%
  dplyr::select(.id, estimate, term) %>%
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>%
  janitor::clean_names() %>%
  mutate(log_beta = log(intercept*tmin))

betas_df

# graph of log_beta 

logbeta_graph = 
  ggplot(betas_df, aes(x = log_beta, color = log_beta)) +
  geom_density()+
  labs(
    x = "Log of Beta0*Beta1",
    y = "Density",
    title = "Log of Beta0*Beta1 Across Bootstrap Samples"
  )

print(logbeta_graph)

# finding 2.5% and 97.5% quantiles for log_beta

quantile(pull(betas_df, log_beta), 0.025)
quantile(pull(betas_df, log_beta), 0.975)


```
The distribution of our ${r}^2$ and $log(\hat{\beta_0}*\hat{\beta_1})$ plots are nearly normally distributed. The ${r}^2$ distribution is slightly skewed right, and the $log(\hat{\beta_0}*\hat{\beta_1})$ is slightly more normalized. The log transformation distribution is slightly more normalized as a log transformation normalizes the distribution.

The 95% confidence interval for the ${r}^2$ values is `r quantile(pull(rsq_df, r_squared), 0.025)` to `r quantile(pull(rsq_df, r_squared), 0.975)`. The null of zero is not contained, so we are 95% confident that the true ${r}^2$ value for our sample lies in this range.
The 95% confidence interval for the $log(\hat{\beta_0}*\hat{\beta_1})$ is 
`r quantile(pull(betas_df, log_beta), 0.025)` to `r quantile(pull(betas_df, log_beta), 0.975)`. The null of zero of not contained, so we are 95% confident that the true $log(\hat{\beta_0}*\hat{\beta_1})$ value for our sample lies in this range.